# app/agent/tools/graph/subgraph_registry.py
"""
Subgraph Registry - ç®€åŒ–ç‰ˆ
æœ¬è´¨ä¸Šå°±æ˜¯ (protocol, network, version) â†’ subgraph_id çš„æ˜ å°„ç¼“å­˜
"""

import json
import logging
from typing import Optional, Dict, List
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

from app.agent.tools.graph.graph_config import CACHE_SETTINGS

logger = logging.getLogger(__name__)

@dataclass
class SubgraphRecord:
    """å­å›¾è®°å½• - æç®€ç‰ˆ"""
    # === æŸ¥æ‰¾é”® ===
    protocol: str           # "uniswap"
    network: str           # "ethereum" 
    version: Optional[str]  # "v3"
    
    # === æ ¸å¿ƒå€¼ ===
    subgraph_id: str       # "5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV"
    name: str              # "Uniswap V3"
    
    # === å¯é€‰å…ƒä¿¡æ¯ ===
    health_status: str = "unknown"
    last_checked: Optional[datetime] = None
    query_count: int = 0
    
    def __post_init__(self):
        if self.last_checked is None:
            self.last_checked = datetime.now()
    
    @property
    def cache_key(self) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        parts = [self.protocol, self.network]
        if self.version:
            parts.append(self.version)
        return "-".join(parts)
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "protocol": self.protocol,
            "network": self.network,
            "version": self.version,
            "subgraph_id": self.subgraph_id,
            "name": self.name,
            "health_status": self.health_status,
            "last_checked": self.last_checked.isoformat() if self.last_checked else None,
            "query_count": self.query_count
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'SubgraphRecord':
        """ä»å­—å…¸åˆ›å»º"""
        last_checked = None
        if data.get('last_checked'):
            last_checked = datetime.fromisoformat(data['last_checked'])
        
        return cls(
            protocol=data['protocol'],
            network=data['network'],
            version=data.get('version'),
            subgraph_id=data['subgraph_id'],
            name=data['name'],
            health_status=data.get('health_status', 'unknown'),
            last_checked=last_checked,
            query_count=data.get('query_count', 0)
        )

class SubgraphRegistry:
    """å­å›¾æ³¨å†Œè¡¨ - ç®€åŒ–ç‰ˆç¼“å­˜"""
    
    def __init__(self, cache_dir: Optional[str] = None):
        self.cache_dir = Path(cache_dir or CACHE_SETTINGS["cache_dir"])
        self.cache_dir.mkdir(exist_ok=True)
        self.registry_file = self.cache_dir / "subgraph_cache.json"
        
        # å†…å­˜ç¼“å­˜ï¼škey -> SubgraphRecord
        self.cache: Dict[str, SubgraphRecord] = {}
        
        # åŠ è½½ç¼“å­˜
        self._load_cache()
    
    def find(self, protocol: str, network: str, version: Optional[str] = None) -> Optional[str]:
        """
        æŸ¥æ‰¾ subgraph_id
        
        Args:
            protocol: åè®®å (å¦‚ "uniswap")
            network: ç½‘ç»œå (å¦‚ "ethereum")
            version: ç‰ˆæœ¬å· (å¦‚ "v3", å¯é€‰)
            
        Returns:
            subgraph_id æˆ– None
        """
        # 1. ç²¾ç¡®åŒ¹é… (protocol + network + version)
        if version:
            key = f"{protocol}-{network}-{version}"
            if key in self.cache:
                record = self.cache[key]
                record.query_count += 1
                logger.info(f"âœ… ç²¾ç¡®åŒ¹é…: {key} â†’ {record.subgraph_id}")
                return record.subgraph_id
        
        # 2. åè®® + ç½‘ç»œåŒ¹é… (å¿½ç•¥ç‰ˆæœ¬)
        key = f"{protocol}-{network}"
        if key in self.cache:
            record = self.cache[key]
            record.query_count += 1
            logger.info(f"âœ… åè®®åŒ¹é…: {key} â†’ {record.subgraph_id}")
            return record.subgraph_id
        
        # 3. æ¨¡ç³ŠåŒ¹é… (æ‰¾åˆ°åŒåè®®çš„ä»»æ„ç‰ˆæœ¬)
        for cache_key, record in self.cache.items():
            if record.protocol == protocol and record.network == network:
                record.query_count += 1
                logger.info(f"âœ… æ¨¡ç³ŠåŒ¹é…: {cache_key} â†’ {record.subgraph_id}")
                return record.subgraph_id
        
        logger.info(f"âŒ æœªæ‰¾åˆ°: {protocol}-{network}-{version}")
        return None
    
    def add(self, protocol: str, network: str, subgraph_id: str, name: str, 
            version: Optional[str] = None, **kwargs) -> bool:
        """
        æ·»åŠ æ–°çš„æ˜ å°„å…³ç³»
        
        Args:
            protocol: åè®®å
            network: ç½‘ç»œå
            subgraph_id: å­å›¾ID
            name: å­å›¾åç§°
            version: ç‰ˆæœ¬å· (å¯é€‰)
            **kwargs: å…¶ä»–å¯é€‰å‚æ•°
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            record = SubgraphRecord(
                protocol=protocol.lower(),
                network=network.lower(),
                version=version.lower() if version else None,
                subgraph_id=subgraph_id,
                name=name,
                **kwargs
            )
            
            cache_key = record.cache_key
            self.cache[cache_key] = record
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_cache()
            
            logger.info(f"âœ… æ·»åŠ æ˜ å°„: {cache_key} â†’ {subgraph_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ˜ å°„å¤±è´¥: {e}")
            return False
    
    def remove(self, protocol: str, network: str, version: Optional[str] = None) -> bool:
        """ç§»é™¤æ˜ å°„å…³ç³»"""
        parts = [protocol, network]
        if version:
            parts.append(version)
        key = "-".join(parts)
        
        if key in self.cache:
            del self.cache[key]
            self._save_cache()
            logger.info(f"âœ… ç§»é™¤æ˜ å°„: {key}")
            return True
        
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è¦ç§»é™¤çš„æ˜ å°„: {key}")
        return False
    
    def update_health(self, protocol: str, network: str, health_status: str, 
                     version: Optional[str] = None):
        """æ›´æ–°å¥åº·çŠ¶æ€"""
        parts = [protocol, network]
        if version:
            parts.append(version)
        key = "-".join(parts)
        
        if key in self.cache:
            self.cache[key].health_status = health_status
            self.cache[key].last_checked = datetime.now()
            self._save_cache()
            logger.info(f"âœ… æ›´æ–°å¥åº·çŠ¶æ€: {key} â†’ {health_status}")
    
    def get_all_protocols(self) -> List[str]:
        """è·å–æ‰€æœ‰åè®®åç§°"""
        protocols = set()
        for record in self.cache.values():
            protocols.add(record.protocol)
        return list(protocols)
    
    def get_protocol_networks(self, protocol: str) -> List[str]:
        """è·å–æŒ‡å®šåè®®æ”¯æŒçš„ç½‘ç»œ"""
        networks = set()
        for record in self.cache.values():
            if record.protocol == protocol:
                networks.add(record.network)
        return list(networks)
    
    def get_statistics(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_records = len(self.cache)
        
        # æŒ‰åè®®ç»Ÿè®¡
        protocol_stats = {}
        network_stats = {}
        health_stats = {"unknown": 0, "healthy": 0, "unhealthy": 0}
        
        for record in self.cache.values():
            # åè®®ç»Ÿè®¡
            protocol_stats[record.protocol] = protocol_stats.get(record.protocol, 0) + 1
            
            # ç½‘ç»œç»Ÿè®¡
            network_stats[record.network] = network_stats.get(record.network, 0) + 1
            
            # å¥åº·çŠ¶æ€ç»Ÿè®¡
            status = record.health_status
            if status in health_stats:
                health_stats[status] += 1
        
        # æœ€å¸¸ç”¨çš„å­å›¾
        most_used = sorted(self.cache.values(), key=lambda x: x.query_count, reverse=True)[:5]
        
        return {
            "total_records": total_records,
            "protocols": protocol_stats,
            "networks": network_stats,
            "health_status": health_stats,
            "most_used": [
                {
                    "key": record.cache_key,
                    "name": record.name,
                    "query_count": record.query_count
                }
                for record in most_used
            ]
        }
    
    def _load_cache(self):
        """ä»æ–‡ä»¶åŠ è½½ç¼“å­˜"""
        try:
            if self.registry_file.exists():
                with open(self.registry_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
                if data.get('version') != '1.0':
                    logger.info("ç¼“å­˜ç‰ˆæœ¬ä¸å…¼å®¹ï¼Œé‡æ–°åˆå§‹åŒ–")
                    self._init_default_cache()
                    return
                
                # åŠ è½½è®°å½•
                for key, record_data in data.get('records', {}).items():
                    try:
                        record = SubgraphRecord.from_dict(record_data)
                        self.cache[key] = record
                    except Exception as e:
                        logger.error(f"åŠ è½½è®°å½•å¤±è´¥ {key}: {e}")
                
                logger.info(f"âœ… åŠ è½½äº† {len(self.cache)} ä¸ªç¼“å­˜è®°å½•")
            else:
                # é¦–æ¬¡è¿è¡Œï¼Œåˆå§‹åŒ–é»˜è®¤ç¼“å­˜
                self._init_default_cache()
                
        except Exception as e:
            logger.error(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            self._init_default_cache()
    
    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            data = {
                'version': '1.0',
                'last_update': datetime.now().isoformat(),
                'records': {
                    key: record.to_dict()
                    for key, record in self.cache.items()
                }
            }
            
            with open(self.registry_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"ğŸ’¾ ä¿å­˜äº† {len(self.cache)} ä¸ªç¼“å­˜è®°å½•")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def _init_default_cache(self):
        """åˆå§‹åŒ–é»˜è®¤ç¼“å­˜"""
        logger.info("ğŸš€ åˆå§‹åŒ–é»˜è®¤å­å›¾ç¼“å­˜...")
        
        # ä¸€äº›å·²çŸ¥çš„å­å›¾æ˜ å°„
        default_mappings = [
            {
                "protocol": "uniswap",
                "network": "ethereum",
                "version": "v3",
                "subgraph_id": "5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV",
                "name": "Uniswap V3"
            }
        ]
        
        for mapping in default_mappings:
            self.add(**mapping)
        
        logger.info(f"âœ… åˆå§‹åŒ–äº† {len(default_mappings)} ä¸ªé»˜è®¤æ˜ å°„")