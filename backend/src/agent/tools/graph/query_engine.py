# app/agent/tools/graph/query_engine.py
"""
æŸ¥è¯¢å¼•æ“ - ç®€åŒ–ç‰ˆï¼Œåªè´Ÿè´£æ‰§è¡Œ GraphQL æŸ¥è¯¢
ä¸å†å¤„ç†åè®®åˆ†æï¼Œä¸“æ³¨äºæŸ¥è¯¢æ‰§è¡Œ
"""

import logging
from typing import Dict, Any, Optional
from datetime import datetime, timedelta

from app.agent.tools.graph.graph_client import graph_client
from app.agent.tools.graph.graph_config import CACHE_SETTINGS

logger = logging.getLogger(__name__)

class QueryEngine:
    """æŸ¥è¯¢å¼•æ“ - æ¥æ”¶ä¸Šä¸‹æ–‡ï¼Œè°ƒç”¨ GraphQL Builderï¼Œæ‰§è¡ŒæŸ¥è¯¢"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“"""
        self.cache = {}
        self.cache_ttl = CACHE_SETTINGS["ttl"]
    
    def execute_natural_language_query(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œè‡ªç„¶è¯­è¨€æŸ¥è¯¢ - æ–°çš„ä¸»è¦æ–¹æ³•
        
        Args:
            context: åŒ…å«ä»¥ä¸‹ä¿¡æ¯çš„ä¸Šä¸‹æ–‡å­—å…¸
                - user_query: ç”¨æˆ·æŸ¥è¯¢
                - protocol: åè®®å
                - network: ç½‘ç»œå  
                - version: ç‰ˆæœ¬å·
                - subgraph_id: å­å›¾ID
                - confidence: ç½®ä¿¡åº¦
                - source: æ¥æº
                - analysis_result: åˆ†æç»“æœ
                
        Returns:
            åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸
        """
        try:
            logger.info(f"ğŸ”§ Query Engine æ¥æ”¶ä¸Šä¸‹æ–‡: {context['protocol']} on {context['network']}")
            
            # Step 5: è°ƒç”¨ GraphQL Builder
            from app.agent.tools.graph.graphql_builder import graphql_builder
            
            # æ„å»ºåè®®ä¸Šä¸‹æ–‡ç»™ GraphQL Builder
            protocol_context = {
                "name": f"{context['protocol'].title()} Protocol",
                "network": context["network"],
                "description": f"{context['protocol'].title()} Protocol on {context['network'].title()}",
                "entities": [],  # GraphQL Builder ä¼šè‡ªå·±æ¨æµ‹
                "categories": ["DeFi"]
            }
            
            logger.info(f"ğŸ—ï¸ è°ƒç”¨ GraphQL Builder...")
            query_result = graphql_builder.build_query(
                natural_language_query=context["user_query"],
                protocol_context=protocol_context
            )
            
            if not query_result or not query_result.get("query"):
                return {
                    "success": False,
                    "error": "GraphQL Builder æ„å»ºæŸ¥è¯¢å¤±è´¥",
                    "formatted_result": ""
                }
            
            logger.info(f"âœ… GraphQL æ„å»ºæˆåŠŸ")
            logger.info(f"ğŸ“„ æŸ¥è¯¢: {query_result['query']}")
            logger.info(f"ğŸ“Š å˜é‡: {query_result.get('variables', {})}")
            
            # Step 6: æ‰§è¡Œ GraphQL æŸ¥è¯¢
            result = self.execute_query(
                subgraph_id=context["subgraph_id"],
                query=query_result["query"],
                variables=query_result.get("variables", {})
            )
            
            if not result:
                return {
                    "success": False,
                    "error": "GraphQL æŸ¥è¯¢æ‰§è¡Œå¤±è´¥",
                    "formatted_result": ""
                }
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_result = graphql_builder.format_result(
                result,
                {
                    "explanation": query_result.get("explanation", ""),
                    "original_query": context["user_query"]
                }
            )
            
            return {
                "success": True,
                "data": result,
                "formatted_result": formatted_result,
                "query_context": {
                    "explanation": query_result.get("explanation", ""),
                    "graphql_query": query_result["query"],
                    "variables": query_result.get("variables", {}),
                    "subgraph_id": context["subgraph_id"],
                    "protocol": context["protocol"],
                    "network": context["network"]
                }
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œè‡ªç„¶è¯­è¨€æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "formatted_result": f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}"
            }
    
    def execute_query(
        self,
        subgraph_id: str,
        query: str,
        variables: Optional[Dict[str, Any]] = None,
        use_cache: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        æ‰§è¡Œ GraphQL æŸ¥è¯¢
        
        Args:
            subgraph_id: å­å›¾ ID
            query: GraphQL æŸ¥è¯¢å­—ç¬¦ä¸²
            variables: æŸ¥è¯¢å˜é‡
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and CACHE_SETTINGS["enabled"]:
            cache_key = f"{subgraph_id}:{hash(query)}:{hash(str(variables))}"
            if cache_key in self.cache:
                cached_data, cached_time = self.cache[cache_key]
                if datetime.now() - cached_time < timedelta(seconds=self.cache_ttl):
                    logger.debug("ä½¿ç”¨ç¼“å­˜æ•°æ®")
                    return cached_data
        
        # è®°å½•æŸ¥è¯¢è¯¦æƒ…
        logger.info(f"æ‰§è¡Œ GraphQL æŸ¥è¯¢åˆ° Subgraph: {subgraph_id}")
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = graph_client.execute_query(
            subgraph_id=subgraph_id,
            query=query,
            variables=variables
        )
        
        # ç¼“å­˜ç»“æœ
        if result and use_cache and CACHE_SETTINGS["enabled"]:
            self.cache[cache_key] = (result, datetime.now())
            
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            self._cleanup_cache()
        
        return result
    
    def execute_with_context(
        self,
        subgraph_id: str,
        query: str,
        variables: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›åŒ…å«ä¸Šä¸‹æ–‡çš„ç»“æœ
        
        Args:
            subgraph_id: å­å›¾ ID
            query: GraphQL æŸ¥è¯¢å­—ç¬¦ä¸²
            variables: æŸ¥è¯¢å˜é‡
            context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            åŒ…å«æŸ¥è¯¢ç»“æœå’Œä¸Šä¸‹æ–‡çš„å­—å…¸
        """
        try:
            logger.info("="*60)
            logger.info("æ‰§è¡Œ GraphQL æŸ¥è¯¢:")
            logger.info(f"Subgraph ID: {subgraph_id}")
            logger.info(f"GraphQL æŸ¥è¯¢:\n{query}")
            logger.info(f"å˜é‡: {variables}")
            if context:
                logger.info(f"ä¸Šä¸‹æ–‡: {context}")
            logger.info("="*60)
            
            result = self.execute_query(subgraph_id, query, variables)
            
            if not result:
                return {
                    "success": False,
                    "error": "æŸ¥è¯¢æ‰§è¡Œå¤±è´¥",
                    "data": None,
                    "context": context or {}
                }
            
            return {
                "success": True,
                "data": result,
                "context": {
                    **(context or {}),
                    "subgraph_id": subgraph_id,
                    "query": query,
                    "variables": variables,
                    "executed_at": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "data": None,
                "context": context or {}
            }
    
    def test_connection(self, subgraph_id: str) -> bool:
        """
        æµ‹è¯•ä¸å­å›¾çš„è¿æ¥
        
        Args:
            subgraph_id: å­å›¾ ID
            
        Returns:
            æ˜¯å¦è¿æ¥æˆåŠŸ
        """
        test_query = """
        query TestConnection {
            _meta {
                block {
                    number
                    timestamp
                }
                deployment
                hasIndexingErrors
            }
        }
        """
        
        try:
            result = self.execute_query(
                subgraph_id=subgraph_id,
                query=test_query,
                use_cache=False
            )
            
            return result is not None and "_meta" in result
            
        except Exception as e:
            logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def get_subgraph_metadata(self, subgraph_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å­å›¾å…ƒæ•°æ®
        
        Args:
            subgraph_id: å­å›¾ ID
            
        Returns:
            å­å›¾å…ƒæ•°æ®
        """
        meta_query = """
        query GetMetadata {
            _meta {
                block {
                    number
                    timestamp
                    hash
                }
                deployment
                hasIndexingErrors
            }
        }
        """
        
        try:
            result = self.execute_query(
                subgraph_id=subgraph_id,
                query=meta_query,
                use_cache=False
            )
            
            if result and "_meta" in result:
                meta = result["_meta"]
                
                # æ ¼å¼åŒ–æ—¶é—´æˆ³
                if meta.get("block", {}).get("timestamp"):
                    timestamp = int(meta["block"]["timestamp"])
                    meta["block"]["formatted_time"] = datetime.fromtimestamp(timestamp).isoformat()
                
                return meta
            
            return None
            
        except Exception as e:
            logger.error(f"è·å–å…ƒæ•°æ®å¤±è´¥: {e}")
            return None
    
    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        now = datetime.now()
        expired_keys = [
            key for key, (_, time) in self.cache.items()
            if now - time > timedelta(seconds=self.cache_ttl)
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        if expired_keys:
            logger.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜")
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.cache.clear()
        logger.info("å·²æ¸…ç©ºæŸ¥è¯¢ç¼“å­˜")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "cache_size": len(self.cache),
            "cache_enabled": CACHE_SETTINGS["enabled"],
            "cache_ttl": self.cache_ttl
        }

# å…¨å±€æŸ¥è¯¢å¼•æ“å®ä¾‹
query_engine = QueryEngine()